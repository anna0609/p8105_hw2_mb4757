---
title: "Homework 2"
author: Minjie Bao
output: github_document
---

```{r setup, message=FALSE}
library(tidyverse)
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

```{r transhwheel}
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
         )
```

Read precipitation data! For 2018 and 2017.

```{r}
precip_2018 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation.

```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )
precip_df = 
  bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data.


## Problem 2
Read and clean the data, covert entry variable from char to logical
```{r NYC_Transit}
nyc_df = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select (line, station_name, station_latitude, station_longitude, entry, route1:route11, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE"), entry = as.logical(entry))

skimr::skim(nyc_df)
names(nyc_df)
```

This dataset contains information from the NYC Transit data; in particular, it has information related to each entrance and exit for each subway station in NYC. There are 19 variables in this dataset: `r names(nyc_df)`.
For data cleaning steps, I clean the variables' name first. Then I select important variables and drop unnecessary variables. After that I convert variable entry from character to logical data type. 

The rows of the dataset is `r nrow(nyc_df)` and the columns of the dataset is `r ncol(nyc_df)`. The dimention is `r nrow(nyc_df)` * `r ncol(nyc_df)`. 

The data is not super tidy since we need to reformat variables route1 to route11.

```{r distinct stations}
distinct_data1 = distinct(nyc_df, line, station_name, .keep_all = TRUE) 
nrow(distinct_data1)
```
There are `r nrow(distinct_data1)` distinct stations here.

```{r ADA compliant}
  filter(distinct_data1,  ada == "TRUE") %>% 
  nrow()
```
There are `r nrow(filter(distinct_data1,  ada == "TRUE"))` stations are ADA compliant.

```{r}
filter(nyc_df,  vending == "NO")
a = nrow(filter(nyc_df,  vending == "NO")) ##the number of station entrances / exits without vending
b = nrow(filter(nyc_df,  vending == "NO", entry == "TRUE")) ##the number of stations entrances / exits that allow entrance but do not have vending
b/a ##The proportion of station entrances / exits without vending allow entrance
```
The proportion of station entrances / exits without vending allow entrance is `r b/a`.

convert variable route9-route11 from double to char.
```{r convert variables}
nyc_df_char = mutate(nyc_df, route8 = as.character(route8),
                route9 = as.character(route9),
                route10 = as.character(route10),
                route11 = as.character(route11)
                )
```

reform the dataset.
```{r nyc_df_tidy}
nyc_df_tidy =
  nyc_df_char %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_name"
  )
```

```{r}
distinct_data2 = distinct(nyc_df_tidy, line, station_name, .keep_all = TRUE)
filter(distinct_data2,  route_name == "A") %>% 
  nrow()
```
There are `r nrow(filter(distinct_data2,  route_name == "A"))` distinct station.

```{r}
filter(distinct_data2,  route_name == "A", ada == "TRUE") %>% 
  nrow()
```
There are `r nrow(filter(distinct_data2,  route_name == "A", ada == "TRUE"))` ada compliant of the stations serve the A train.


## Problem 3
read the csv datasets
```{r}
pols_month_df = 
  read_csv("./data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, 
           into = c("year", "month", "day"),
           convert = TRUE
           ) %>% 
 mutate(
   month = month.abb[as.factor(month)],
   president = case_when(
     prez_gop == 1 ~ 'gop',
     prez_dem == 1 ~ 'dem'
   ) 
   ) %>% 
  arrange(year, month) %>%
  select(-prez_dem, -prez_gop, -day)
```

clean snap data
```{r}
snap_df = 
read_csv("./data/snp.csv") %>% 
  janitor::clean_names() %>% 
 separate(date, 
          into = c("month", "day","year"),
          sep = "/",
          convert = TRUE
          ) %>% 
 mutate( month = month.abb[as.factor(month)]) %>% 
  arrange(year, month) %>% 
  select(year, month, close)
```

clean the unemployment data
```{r}
unemployment_df = 
  read_csv("./data/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_rate"
  ) %>% 
  mutate( month = month.abb[as.factor(month)])
```

merge the files
```{r}
merge_pols_snap = left_join(pols_month_df, snap_df, by = c("year","month"))
merge_all =left_join(merge_pols_snap, unemployment_df, by = c("year","month"))
```


