Homework 2
================
Minjie Bao

``` r
library(tidyverse)
```

    ## ── Attaching packages ───────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ──────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
         )
```

Read precipitation data\! For 2018 and 2017.

``` r
precip_2018 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )
precip_df = 
  bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data.

## Problem 2

Read and clean the data, covert entry from char to logical

``` r
nyc_df = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") 
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
nyc_df = janitor::clean_names(nyc_df)
nyc_df = select (nyc_df, line, station_name, station_latitude, station_longitude, entry, route1:route11, vending, entrance_type, ada)
nyc_df = mutate(nyc_df, entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE"), entry = as.logical(entry))
skimr::skim(nyc_df)
```

|                                                  |         |
| :----------------------------------------------- | :------ |
| Name                                             | nyc\_df |
| Number of rows                                   | 1868    |
| Number of columns                                | 19      |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |         |
| Column type frequency:                           |         |
| character                                        | 11      |
| logical                                          | 2       |
| numeric                                          | 6       |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |         |
| Group variables                                  | None    |

Data summary

**Variable type: character**

| skim\_variable | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
| :------------- | ---------: | -------------: | --: | --: | ----: | --------: | ---------: |
| line           |          0 |           1.00 |   5 |  17 |     0 |        36 |          0 |
| station\_name  |          0 |           1.00 |   4 |  39 |     0 |       356 |          0 |
| route1         |          0 |           1.00 |   1 |   2 |     0 |        24 |          0 |
| route2         |        848 |           0.55 |   1 |   2 |     0 |        20 |          0 |
| route3         |       1374 |           0.26 |   1 |   2 |     0 |        18 |          0 |
| route4         |       1547 |           0.17 |   1 |   1 |     0 |        13 |          0 |
| route5         |       1630 |           0.13 |   1 |   1 |     0 |        12 |          0 |
| route6         |       1741 |           0.07 |   1 |   1 |     0 |         7 |          0 |
| route7         |       1788 |           0.04 |   1 |   2 |     0 |         7 |          0 |
| vending        |          0 |           1.00 |   2 |   3 |     0 |         2 |          0 |
| entrance\_type |          0 |           1.00 |   4 |   9 |     0 |         7 |          0 |

**Variable type: logical**

| skim\_variable | n\_missing | complete\_rate | mean | count               |
| :------------- | ---------: | -------------: | ---: | :------------------ |
| entry          |          0 |              1 | 0.94 | TRU: 1753, FAL: 115 |
| ada            |          0 |              1 | 0.25 | FAL: 1400, TRU: 468 |

**Variable type: numeric**

| skim\_variable     | n\_missing | complete\_rate |    mean |   sd |      p0 |     p25 |     p50 |     p75 |    p100 | hist  |
| :----------------- | ---------: | -------------: | ------: | ---: | ------: | ------: | ------: | ------: | ------: | :---- |
| station\_latitude  |          0 |           1.00 |   40.73 | 0.07 |   40.58 |   40.69 |   40.73 |   40.77 |   40.90 | ▂▅▇▃▂ |
| station\_longitude |          0 |           1.00 | \-73.94 | 0.06 | \-74.03 | \-73.99 | \-73.96 | \-73.91 | \-73.76 | ▇▆▃▂▁ |
| route8             |       1820 |           0.03 |    2.98 | 1.94 |    1.00 |    1.00 |    4.00 |    5.00 |    5.00 | ▇▁▁▂▇ |
| route9             |       1840 |           0.01 |    2.54 | 1.17 |    2.00 |    2.00 |    2.00 |    2.00 |    5.00 | ▇▁▁▁▂ |
| route10            |       1845 |           0.01 |    3.00 | 0.00 |    3.00 |    3.00 |    3.00 |    3.00 |    3.00 | ▁▁▇▁▁ |
| route11            |       1845 |           0.01 |    7.00 | 0.00 |    7.00 |    7.00 |    7.00 |    7.00 |    7.00 | ▁▁▇▁▁ |

This dataset contains information from the NYC Transit data; in
particular, it has information related to each entrance and exit for
each subway station in NYC. There are 19 variables in this dataset
includes line, station name, entry and route served etc. For data
cleaning steps, I read the data first and usejanitor to clean the
variables’ name. Then I change the variable entry from character to
logical. Finally, I use skimr to take a brief view of the descriptive
statistics of the dataset. The dimention(rows x columns) of the dataset
is 1868 \* 19. The data is tidy since columns are variables, rows are
observations and every value has a cell.

``` r
distinct_data1 = distinct(nyc_df, line, station_name, .keep_all = TRUE)
```

There are 465 distinct stations here.

``` r
filter(distinct_data1,  ada == "TRUE")
```

    ## # A tibble: 84 x 19
    ##    line  station_name station_latitude station_longitu… entry route1 route2
    ##    <chr> <chr>                   <dbl>            <dbl> <lgl> <chr>  <chr> 
    ##  1 4 Av… Atlantic Av…             40.7            -74.0 TRUE  B      Q     
    ##  2 4 Av… DeKalb Av                40.7            -74.0 TRUE  B      Q     
    ##  3 4 Av… Pacific St               40.7            -74.0 TRUE  B      Q     
    ##  4 42nd… Grand Centr…             40.8            -74.0 TRUE  GS     4     
    ##  5 6 Av… 34th St                  40.7            -74.0 TRUE  B      D     
    ##  6 6 Av… 47-50th Sts…             40.8            -74.0 TRUE  B      D     
    ##  7 6 Av… Church Av                40.6            -74.0 TRUE  F      <NA>  
    ##  8 63rd… 21st St                  40.8            -73.9 TRUE  F      <NA>  
    ##  9 63rd… Lexington Av             40.8            -74.0 TRUE  F      <NA>  
    ## 10 63rd… Roosevelt I…             40.8            -74.0 TRUE  F      <NA>  
    ## # … with 74 more rows, and 12 more variables: route3 <chr>, route4 <chr>,
    ## #   route5 <chr>, route6 <chr>, route7 <chr>, route8 <dbl>, route9 <dbl>,
    ## #   route10 <dbl>, route11 <dbl>, vending <chr>, entrance_type <chr>, ada <lgl>

There are 84 stations are ADA compliant.

``` r
filter(nyc_df,  vending == "NO")
```

    ## # A tibble: 183 x 19
    ##    line  station_name station_latitude station_longitu… entry route1 route2
    ##    <chr> <chr>                   <dbl>            <dbl> <lgl> <chr>  <chr> 
    ##  1 4 Av… 53rd St                  40.6            -74.0 FALSE R      <NA>  
    ##  2 4 Av… 77th St                  40.6            -74.0 FALSE R      <NA>  
    ##  3 4 Av… 9th St                   40.7            -74.0 TRUE  F      G     
    ##  4 4 Av… Bay Ridge Av             40.6            -74.0 FALSE R      <NA>  
    ##  5 42nd… Grand Centr…             40.8            -74.0 FALSE GS     4     
    ##  6 42nd… Grand Centr…             40.8            -74.0 FALSE GS     4     
    ##  7 6 Av… 7th Av                   40.7            -74.0 TRUE  F      <NA>  
    ##  8 6 Av… 7th Av                   40.7            -74.0 TRUE  F      <NA>  
    ##  9 6 Av… 7th Av                   40.7            -74.0 TRUE  F      <NA>  
    ## 10 6 Av… 7th Av                   40.7            -74.0 TRUE  F      <NA>  
    ## # … with 173 more rows, and 12 more variables: route3 <chr>, route4 <chr>,
    ## #   route5 <chr>, route6 <chr>, route7 <chr>, route8 <dbl>, route9 <dbl>,
    ## #   route10 <dbl>, route11 <dbl>, vending <chr>, entrance_type <chr>, ada <lgl>

``` r
a = nrow(filter(nyc_df,  vending == "NO"))
b = nrow(nyc_df)
a/b ##The proportion of station entrances / exits without vending allow entrance
```

    ## [1] 0.09796574

The proportion of station entrances / exits without vending allow
entrance is 0.0979657.

convert variable route9-route11 from double to char.

``` r
nyc_df_char = mutate(nyc_df, route8 = as.character(route8),
                route9 = as.character(route9),
                route10 = as.character(route10),
                route11 = as.character(route11)
                )
```

reform the data.

``` r
nyc_df_tidy =
  nyc_df_char %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_name"
  )
```

``` r
distinct_data2 = distinct(nyc_df_tidy, line, station_name, .keep_all = TRUE)
filter(distinct_data2,  route_name == "A")
```

    ## # A tibble: 60 x 10
    ##    line  station_name station_latitude station_longitu… entry vending
    ##    <chr> <chr>                   <dbl>            <dbl> <lgl> <chr>  
    ##  1 42nd… Times Square             40.8            -74.0 TRUE  YES    
    ##  2 8 Av… 125th St                 40.8            -74.0 TRUE  YES    
    ##  3 8 Av… 145th St                 40.8            -73.9 TRUE  YES    
    ##  4 8 Av… 14th St                  40.7            -74.0 TRUE  YES    
    ##  5 8 Av… 168th St - …             40.8            -73.9 TRUE  YES    
    ##  6 8 Av… 175th St                 40.8            -73.9 TRUE  YES    
    ##  7 8 Av… 181st St                 40.9            -73.9 TRUE  YES    
    ##  8 8 Av… 190th St                 40.9            -73.9 TRUE  YES    
    ##  9 8 Av… 34th St                  40.8            -74.0 TRUE  YES    
    ## 10 8 Av… 42nd St                  40.8            -74.0 TRUE  YES    
    ## # … with 50 more rows, and 4 more variables: entrance_type <chr>, ada <lgl>,
    ## #   route_number <chr>, route_name <chr>

There are 60 distinct station.

``` r
filter(distinct_data2,  route_name == "A", ada == "TRUE")
```

    ## # A tibble: 17 x 10
    ##    line  station_name station_latitude station_longitu… entry vending
    ##    <chr> <chr>                   <dbl>            <dbl> <lgl> <chr>  
    ##  1 8 Av… 14th St                  40.7            -74.0 TRUE  YES    
    ##  2 8 Av… 168th St - …             40.8            -73.9 TRUE  YES    
    ##  3 8 Av… 175th St                 40.8            -73.9 TRUE  YES    
    ##  4 8 Av… 34th St                  40.8            -74.0 TRUE  YES    
    ##  5 8 Av… 42nd St                  40.8            -74.0 TRUE  YES    
    ##  6 8 Av… 59th St                  40.8            -74.0 TRUE  YES    
    ##  7 8 Av… Inwood - 20…             40.9            -73.9 TRUE  YES    
    ##  8 8 Av… West 4th St              40.7            -74.0 TRUE  YES    
    ##  9 8 Av… World Trade…             40.7            -74.0 TRUE  YES    
    ## 10 Broa… Times Squar…             40.8            -74.0 TRUE  YES    
    ## 11 Broa… 59th St-Col…             40.8            -74.0 TRUE  YES    
    ## 12 Broa… Times Square             40.8            -74.0 TRUE  YES    
    ## 13 Cana… 8th Av                   40.7            -74.0 TRUE  YES    
    ## 14 Fran… Franklin Av              40.7            -74.0 TRUE  YES    
    ## 15 Fult… Euclid Av                40.7            -73.9 TRUE  YES    
    ## 16 Fult… Franklin Av              40.7            -74.0 TRUE  YES    
    ## 17 Rock… Howard Beach             40.7            -73.8 TRUE  YES    
    ## # … with 4 more variables: entrance_type <chr>, ada <lgl>, route_number <chr>,
    ## #   route_name <chr>

There are 17 ada compliant of the stations serve the A train.

## Problem 3

read the csv datasets
